{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropland Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyze the [UCI Cropland Mapping dataset](https://archive.ics.uci.edu/ml/datasets/Crop+mapping+using+fused+optical-radar+data+set). From the UCI Machine Learning Repository, \"This data set is a fused bi-temporal optical-radar data for cropland classification. The images were collected by RapidEye satellites (optical) and the Unmanned Aerial Vehicle Synthetic Aperture Radar (UAVSAR) system (Radar) over an agricultural region near Winnipeg, Manitoba, Canada in 2012.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, this data set provides satellite images of different cropland areas in Winnipeg, Manitoba, Canada. There is also a radar component to the dataset, but as it is a surprisingly large dataset, we will be excluding the radar portion here for simplification purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 x 49 radar features and 2 x 38 optical features for two dates: 05 and 14 July 2012.\n",
    "Seven crop type classes exist for this data set as follows: \n",
    "  * 1) Corn \n",
    "  * 2) Pea \n",
    "  * 3) Canola \n",
    "  * 4) Soybean\n",
    "  * 5) Oat\n",
    "  * 6) Wheat\n",
    "  * 7) Broadleaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = pd.read_csv(\"./WinnipegDataset.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns labeled 'f1' to 'f98' (radar data columns) because we only want to use the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>f101</th>\n",
       "      <th>f102</th>\n",
       "      <th>f103</th>\n",
       "      <th>f104</th>\n",
       "      <th>f105</th>\n",
       "      <th>f106</th>\n",
       "      <th>f107</th>\n",
       "      <th>...</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>f167</th>\n",
       "      <th>f168</th>\n",
       "      <th>f169</th>\n",
       "      <th>f170</th>\n",
       "      <th>f171</th>\n",
       "      <th>f172</th>\n",
       "      <th>f173</th>\n",
       "      <th>f174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.76978</td>\n",
       "      <td>7.6875</td>\n",
       "      <td>1.18750</td>\n",
       "      <td>0.50488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18519</td>\n",
       "      <td>0.72602</td>\n",
       "      <td>5.3333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.29489</td>\n",
       "      <td>9.77780</td>\n",
       "      <td>2.44440</td>\n",
       "      <td>1.67700</td>\n",
       "      <td>0.20988</td>\n",
       "      <td>0.65422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.77370</td>\n",
       "      <td>7.8378</td>\n",
       "      <td>1.18920</td>\n",
       "      <td>0.42041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>-0.48751</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.84869</td>\n",
       "      <td>0.50617</td>\n",
       "      <td>-0.18898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.73256</td>\n",
       "      <td>6.4783</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.40217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25926</td>\n",
       "      <td>0.25298</td>\n",
       "      <td>2.2222</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.68889</td>\n",
       "      <td>0.88889</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>1.27300</td>\n",
       "      <td>0.30864</td>\n",
       "      <td>0.10483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.58659</td>\n",
       "      <td>3.8378</td>\n",
       "      <td>0.95946</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16049</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>4.1111</td>\n",
       "      <td>0.320990</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>1.14910</td>\n",
       "      <td>0.38272</td>\n",
       "      <td>0.41603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.59036</td>\n",
       "      <td>3.8824</td>\n",
       "      <td>0.97059</td>\n",
       "      <td>0.32678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18519</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.68889</td>\n",
       "      <td>0.88889</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>1.58110</td>\n",
       "      <td>0.20988</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    f99   f100   f101   f102   f103     f104    f105     f106  \\\n",
       "0      1  0.009  0.057  0.048  0.165  0.369  0.76978  7.6875  1.18750   \n",
       "1      1  0.001  0.044  0.037  0.103  0.290  0.77370  7.8378  1.18920   \n",
       "2      1  0.001  0.046  0.046  0.107  0.298  0.73256  6.4783  1.00000   \n",
       "3      1  0.018  0.071  0.074  0.120  0.284  0.58659  3.8378  0.95946   \n",
       "4      1  0.023  0.066  0.068  0.131  0.264  0.59036  3.8824  0.97059   \n",
       "\n",
       "      f107  ...     f165     f166    f167      f168     f169     f170  \\\n",
       "0  0.50488  ...  0.18519  0.72602  5.3333  6.000000  0.29489  9.77780   \n",
       "1  0.42041  ...  0.33333 -0.48751  2.1111  0.098765  0.83333  0.33333   \n",
       "2  0.40217  ...  0.25926  0.25298  2.2222  0.172840  0.68889  0.88889   \n",
       "3  0.32957  ...  0.16049  0.43750  4.1111  0.320990  0.83333  0.33333   \n",
       "4  0.32678  ...  0.18519  0.35000  4.0000  0.444440  0.68889  0.88889   \n",
       "\n",
       "      f171     f172     f173     f174  \n",
       "0  2.44440  1.67700  0.20988  0.65422  \n",
       "1  0.33333  0.84869  0.50617 -0.18898  \n",
       "2  0.66667  1.27300  0.30864  0.10483  \n",
       "3  0.33333  1.14910  0.38272  0.41603  \n",
       "4  0.66667  1.58110  0.20988  0.50000  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data = crops.drop(crops.iloc[:, 1:99], axis=1)\n",
    "crop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325834, 77)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>f101</th>\n",
       "      <th>f102</th>\n",
       "      <th>f103</th>\n",
       "      <th>f104</th>\n",
       "      <th>f105</th>\n",
       "      <th>f106</th>\n",
       "      <th>f107</th>\n",
       "      <th>...</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>f167</th>\n",
       "      <th>f168</th>\n",
       "      <th>f169</th>\n",
       "      <th>f170</th>\n",
       "      <th>f171</th>\n",
       "      <th>f172</th>\n",
       "      <th>f173</th>\n",
       "      <th>f174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "      <td>325834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.062421</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.127367</td>\n",
       "      <td>0.416935</td>\n",
       "      <td>0.825873</td>\n",
       "      <td>18.178251</td>\n",
       "      <td>1.702412</td>\n",
       "      <td>0.586187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433834</td>\n",
       "      <td>0.329085</td>\n",
       "      <td>2.171177</td>\n",
       "      <td>0.080138</td>\n",
       "      <td>0.919604</td>\n",
       "      <td>0.174447</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.403288</td>\n",
       "      <td>0.764646</td>\n",
       "      <td>0.667567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.604617</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.025087</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.119339</td>\n",
       "      <td>0.115235</td>\n",
       "      <td>20.225461</td>\n",
       "      <td>0.842595</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>0.442008</td>\n",
       "      <td>1.284653</td>\n",
       "      <td>0.182628</td>\n",
       "      <td>0.105953</td>\n",
       "      <td>0.373726</td>\n",
       "      <td>0.222008</td>\n",
       "      <td>0.480141</td>\n",
       "      <td>0.273847</td>\n",
       "      <td>0.471260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.017964</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.028535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.757060</td>\n",
       "      <td>7.232600</td>\n",
       "      <td>1.234000</td>\n",
       "      <td>0.469630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.506170</td>\n",
       "      <td>0.357140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.846150</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.634270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358020</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.924190</td>\n",
       "      <td>25.381000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.701710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506170</td>\n",
       "      <td>0.661440</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.848690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.444000</td>\n",
       "      <td>25.951000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.667000</td>\n",
       "      <td>6.666700</td>\n",
       "      <td>2.197200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label            f99           f100           f101  \\\n",
       "count  325834.000000  325834.000000  325834.000000  325834.000000   \n",
       "mean        4.062421       0.005373       0.052990       0.037367   \n",
       "std         1.604617       0.006708       0.025087       0.023287   \n",
       "min         1.000000       0.001000       0.001000       0.001000   \n",
       "25%         3.000000       0.001000       0.034000       0.017000   \n",
       "50%         4.000000       0.001000       0.044000       0.032000   \n",
       "75%         6.000000       0.009000       0.067000       0.054000   \n",
       "max         7.000000       0.279000       0.341000       0.321000   \n",
       "\n",
       "                f102           f103           f104           f105  \\\n",
       "count  325834.000000  325834.000000  325834.000000  325834.000000   \n",
       "mean        0.127367       0.416935       0.825873      18.178251   \n",
       "std         0.039231       0.119339       0.115235      20.225461   \n",
       "min         0.001000       0.001000      -0.017964       0.964710   \n",
       "25%         0.098000       0.322000       0.757060       7.232600   \n",
       "50%         0.111000       0.423000       0.846150      12.000000   \n",
       "75%         0.148000       0.497000       0.924190      25.381000   \n",
       "max         0.342000       0.752000       0.996410     556.000000   \n",
       "\n",
       "                f106           f107  ...           f165           f166  \\\n",
       "count  325834.000000  325834.000000  ...  325834.000000  325834.000000   \n",
       "mean        1.702412       0.586187  ...       0.433834       0.329085   \n",
       "std         0.842595       0.153944  ...       0.245857       0.442008   \n",
       "min         0.071429      -0.028535  ...       0.111110      -1.000000   \n",
       "25%         1.234000       0.469630  ...       0.259260       0.000000   \n",
       "50%         1.500000       0.634270  ...       0.358020       0.357140   \n",
       "75%         2.000000       0.701710  ...       0.506170       0.661440   \n",
       "max        34.000000       1.020000  ...       1.000000       1.000000   \n",
       "\n",
       "                f167           f168           f169           f170  \\\n",
       "count  325834.000000  325834.000000  325834.000000  325834.000000   \n",
       "mean        2.171177       0.080138       0.919604       0.174447   \n",
       "std         1.284653       0.182628       0.105953       0.373726   \n",
       "min         0.000000       0.000000       0.106190       0.000000   \n",
       "25%         1.000000       0.000000       0.833330       0.000000   \n",
       "50%         2.000000       0.000000       1.000000       0.000000   \n",
       "75%         3.000000       0.172840       1.000000       0.333330   \n",
       "max        12.444000      25.951000       1.000000      66.667000   \n",
       "\n",
       "                f171           f172           f173           f174  \n",
       "count  325834.000000  325834.000000  325834.000000  325834.000000  \n",
       "mean        0.162900       0.403288       0.764646       0.667567  \n",
       "std         0.222008       0.480141       0.273847       0.471260  \n",
       "min         0.000000      -0.000000       0.111110      -1.000000  \n",
       "25%         0.000000      -0.000000       0.506170       0.357140  \n",
       "50%         0.000000      -0.000000       1.000000       1.000000  \n",
       "75%         0.333330       0.848690       1.000000       1.000000  \n",
       "max         6.666700       2.197200       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 77 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for each of the classes, we have sample sizes:\n",
    "   \n",
    "   * corn: 39,162\n",
    "   * pea: 3,598\n",
    "   * canola: 75,673\n",
    "   * soybean: 74,067\n",
    "   * oat: 47,117\n",
    "   * wheat: 85,074 \n",
    "   * broadleaf: 1,143\n",
    "   \n",
    "out of the total number of samples, 325,834.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little easier to understand if we can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class proportion\n",
      "\n",
      "Class 1: 12.02 %\n",
      "Class 2: 1.10 %\n",
      "Class 3: 23.22 %\n",
      "Class 4: 22.73 %\n",
      "Class 5: 14.46 %\n",
      "Class 6: 26.11 %\n",
      "Class 7: 0.35 %\n"
     ]
    }
   ],
   "source": [
    "class_proportion = pd.Series(100 * crop_data.label.value_counts(normalize=True)).sort_index()\n",
    "print('Class proportion\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_proportion.index[i]}: {class_proportion.iloc[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.bar(['Corn', 'Pea', 'Canola', 'Soy', 'Oat', 'Wheat', 'Broadleaf'], class_proportion, color = ['seagreen','mediumseagreen','springgreen','mediumspringgreen','mediumaquamarine','aquamarine','turquoise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so it looks like the 'Pea' and 'Broadleaf' classes will be the most difficult to classify because we have fewer samples. I expect we will see that in the classification accuracy score for those two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has one column for the class labels ('Corn', 'Pea', 'Canola', 'Soy', 'Oat', 'Wheat', 'Broadleaf'), and 75 columns of features. I will be using an 80/20 train/test split and then a 70/30 train test split and comparing the two accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111',\n",
    "                'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124',\n",
    "                'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137',\n",
    "                'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150',\n",
    "                'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163',\n",
    "                'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174']\n",
    "X = crop_data[features]\n",
    "T = crop_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split: 80/20\n",
      "Training Features Shape: (260667, 76)\n",
      "Training Labels Shape: (260667,)\n",
      "Testing Features Shape: (65167, 76)\n",
      "Testing Labels Shape: (65167,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T, test_size = 0.20)\n",
    "print('Train/Test split: 80/20')\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split: 70/30\n",
      "Training Features Shape: (228083, 76)\n",
      "Training Labels Shape: (228083,)\n",
      "Testing Features Shape: (97751, 76)\n",
      "Testing Labels Shape: (97751,)\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, T, test_size = 0.30)\n",
    "print('Train/Test split: 70/30')\n",
    "print('Training Features Shape:', X_train2.shape)\n",
    "print('Training Labels Shape:', y_train2.shape)\n",
    "print('Testing Features Shape:', X_test2.shape)\n",
    "print('Testing Labels Shape:', y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split the data, let's check how many samples we have to test on in each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count - Test labels: 80/20 split\n",
      "\n",
      "Class 1: 7787\n",
      "Class 2: 699\n",
      "Class 3: 15164\n",
      "Class 4: 14876\n",
      "Class 5: 9373\n",
      "Class 6: 17037\n",
      "Class 7: 231\n"
     ]
    }
   ],
   "source": [
    "class_count = pd.Series(y_test.value_counts()).sort_index()\n",
    "print('Class count - Test labels: 80/20 split\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_count.index[i]}: {class_count.iloc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count - Test labels: 70/30 split\n",
      "\n",
      "Class 1: 11743\n",
      "Class 2: 1141\n",
      "Class 3: 22817\n",
      "Class 4: 22212\n",
      "Class 5: 14077\n",
      "Class 6: 25405\n",
      "Class 7: 356\n"
     ]
    }
   ],
   "source": [
    "class_count = pd.Series(y_test2.value_counts()).sort_index()\n",
    "print('Class count - Test labels: 70/30 split\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_count.index[i]}: {class_count.iloc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn_train = y_train.values\n",
    "yn_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn_train2 = y_train2.values\n",
    "yn_test2 = y_test2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "To classify the data into the classes listed above using a neural network classifier, a gradient boosting classifier, and a random forest classifier. Then we will analyze the accuracy of each of the classifiers and attempt to determine how the accuracy could be improved or why we may be getting that score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multi-layer perceptron classifier (MLP-classifier) from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "nn = mlp.fit(X_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for 80/20 split is 0.9667316279712124\n"
     ]
    }
   ],
   "source": [
    "nn_pred = nn.predict(X_test)\n",
    "nn_acc = accuracy_score(yn_test, nn_pred, normalize=False)\n",
    "print(\"Classification accuracy for 80/20 split is\", nn_acc/len(yn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.67% accuracy for 80/20 split, not bad! Let's see if a 70/30 split can improve that at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.append(('Neural Network', 'Split: 70/30'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "nn2 = mlp.fit(X_train2, yn_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for 70/30 split is 0.9721332774089267\n"
     ]
    }
   ],
   "source": [
    "nn_pred2 = nn.predict(X_test2)\n",
    "nn_acc2 = accuracy_score(yn_test2, nn_pred2, normalize=False)\n",
    "print(\"Classification accuracy for 70/30 split is\", nn_acc2/len(yn_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.21% accuracy for 70/30 split! A slight improvement, but nothing too drastic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_booster = GradientBoostingClassifier(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.97      0.98      7787\n",
      "           2       0.99      0.98      0.98       699\n",
      "           3       1.00      1.00      1.00     15164\n",
      "           4       0.98      0.99      0.98     14876\n",
      "           5       0.85      0.85      0.85      9373\n",
      "           6       0.92      0.92      0.92     17037\n",
      "           7       0.81      0.67      0.73       231\n",
      "\n",
      "    accuracy                           0.95     65167\n",
      "   macro avg       0.93      0.91      0.92     65167\n",
      "weighted avg       0.95      0.95      0.95     65167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grad_booster.fit(X_train, yn_train)\n",
    "grad_pred = grad_booster.predict(X_test)\n",
    "print(classification_report(yn_test, grad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy is 0.9498826092961161\n"
     ]
    }
   ],
   "source": [
    "grad_acc = grad_booster.score(X_test, yn_test)\n",
    "print(\"Classification accuracy is\", grad_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall 94.9% accuracy for a 80/20 split! Classes 5 and 7 (oat and broadleaf) had the lowest classification accuracy. We expected to see this for the broadleaf and pea class because they have the lowest class shares, but the Pea class (class 2) came through with 98% accuracy. But oh my gosh that took forever to run and the accuracy is slightly lower than I had hoped for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the Random Forest with an 80/20 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.append(('Random Forest', 'Split: 80/20'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest = forest.fit(X_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy is 0.9643070879432841\n"
     ]
    }
   ],
   "source": [
    "forest_predict = forest.predict(X_test)\n",
    "forest_acc = accuracy_score(yn_test, forest_predict)\n",
    "print(\"Classification accuracy is\", forest_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.4% accuracy, not bad! Let's see how it performs with a 70/30 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest2 = RandomForestClassifier()\n",
    "forest2 = forest2.fit(X_train2, yn_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy is 0.9619236631850313\n"
     ]
    }
   ],
   "source": [
    "forest_predict2 = forest2.predict(X_test2)\n",
    "forest_acc2 = accuracy_score(yn_test2, forest_predict2)\n",
    "print(\"Classification accuracy is\", forest_acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.19% accuracy, a little worse that we got with the 80/20 split, but still better than the Gradient Booster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['Neural Network - Split: 80/20', 'Neural Network - Split: 70/30', 'Gradient Boosting - Split: 80/20', 'Random Forest - Split: 80/20', 'Random Forest - Split: 70/30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [nn_acc/len(yn_test), nn_acc2/len(yn_test2), grad_acc, forest_acc, forest_acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network - Split: 80/20</td>\n",
       "      <td>Neural Network - Split: 70/30</td>\n",
       "      <td>Gradient Boosting - Split: 80/20</td>\n",
       "      <td>Random Forest - Split: 80/20</td>\n",
       "      <td>Random Forest - Split: 70/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966732</td>\n",
       "      <td>0.972133</td>\n",
       "      <td>0.949883</td>\n",
       "      <td>0.964307</td>\n",
       "      <td>0.961924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                              1  \\\n",
       "0  Neural Network - Split: 80/20  Neural Network - Split: 70/30   \n",
       "1                       0.966732                       0.972133   \n",
       "\n",
       "                                  2                             3  \\\n",
       "0  Gradient Boosting - Split: 80/20  Random Forest - Split: 80/20   \n",
       "1                          0.949883                      0.964307   \n",
       "\n",
       "                              4  \n",
       "0  Random Forest - Split: 70/30  \n",
       "1                      0.961924  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame((model, acc))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been forced to conclude that the Gradient Boosting Classifier just isn't meant for a task like this. From the research that I've done since getting the first accuracy score, it seems like the Gradient Booster works best when it is just trying to classify data into two classes. Here we have 7, so I clearly chose the wrong tool for the job. I had also tried the Gradient Boosting Classifier with a 70/30 split, and got a 94.6% accuracy, but seeing as this is not the correct kind of classifier to be using, keeping that code was just cluttering up my notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that the neural network works! It efficiently classifies the data with a high accuracy. I think my favorite classifier is the Random Forest, despite the accuracy being a little lower than the neural network. I have a little bit of experience using decision trees, and I think that the random forest implementation is a little more intuitive, not to mention faster! Even if the accuracy takes a bit of a hit. My personal preferences aside, the Neural Network with a 70/30 train/test split is the most accurate and was fairly efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have seen some other experiments in which the entire data set was used (including the radar data, which I chose to remove) and they were able to achieve a much higher accuracy (99.29%) with both a neural network implementation and a random forest classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "Breviglieri, Paulo. “Cropland Mapping - Random Forest &amp; Neural Network.” Kaggle, Kaggle, 9 Oct. 2020, https://www.kaggle.com/code/pcbreviglieri/cropland-mapping-random-forest-neural-network/notebook. \n",
    "\n",
    "Khosravi, Iman. “Crop Mapping Using Fused Optical-Radar Data Set.” UCI Machine Learning Repository, 16 June 2020, https://archive.ics.uci.edu/ml/datasets/Crop+mapping+using+fused+optical-radar+data+set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
